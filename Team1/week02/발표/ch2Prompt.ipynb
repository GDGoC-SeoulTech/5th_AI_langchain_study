{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"collapsed_sections":["_j-kesqFpTHe","sdy8wZRu21Nb","P6pq7mTm7yqj","muHRX1GxNYsz","4HENl9A5uwTE"],"authorship_tag":"ABX9TyMMBec5INeAxh8F6YQGG7dZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## 01. 프롬프트(Prompt)"],"metadata":{"id":"WtBFZ4mYsCvm"}},{"cell_type":"markdown","source":["PromptTemplate"],"metadata":{"id":"zvkecrqAPTHs"}},{"cell_type":"code","source":["!pip install -qU langchain-teddynote"],"metadata":{"id":"djq_MKxnXPDb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import userdata\n","import os\n","os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n","os.environ[\"LANGSMITH_API_KEY\"] = userdata.get(\"LANGSMITH_API_KEY\")"],"metadata":{"id":"aQsnAjY-SabB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["이 코드는 API 키를 직접 `os.environ` 딕셔너리에 넣어주기 때문에, `load_dotenv()`를 사용할 필요가 전혀 없습니다."],"metadata":{"id":"C7KAcFsRWf8Q"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"91DswmkYOQ1F"},"outputs":[],"source":["from dotenv import load_dotenv\n","# 이 코드는 Colab 환경에서는 불필요합니다.\n","load_dotenv()\n","# Colab에 .env 파일이 없으므로 False 반환"]},{"cell_type":"code","source":["# LangSmith 추적을 설정합니다. https://smith.langchain.com\n","from langchain_teddynote import logging\n","\n","# 프로젝트 이름을 입력합니다.\n","logging.langsmith(\"CH02-Prompt\")"],"metadata":{"id":"pRTtJVtRXD2H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["LLM 객체를 정의합니다."],"metadata":{"id":"avel72poSaPo"}},{"cell_type":"code","source":["from langchain_openai import ChatOpenAI\n","\n","llm = ChatOpenAI()"],"metadata":{"id":"uRGQwGwAhUZX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## RAG 프롬프트 구조와 기본 PromptTemplate"],"metadata":{"id":"aEtVWeyX7m1O"}},{"cell_type":"markdown","source":["PromptTemplate: {Question}이나 {Context} 같은 변수를 동적으로 채워 넣어 프롬프트를 생성하는 기본 도구"],"metadata":{"id":"6B9q8DRD7zM_"}},{"cell_type":"markdown","source":["1. PromptTemplate.from_template()은 가장 간단하게 템플릿을 생성\n","2. PromptTemplate() 생성자는 input_variables를 명시하여 변수 유효성 검사를 강화"],"metadata":{"id":"0a0OBEjJ8Hxb"}},{"cell_type":"markdown","source":["### 방법 1. from_template() 메소드를 사용하여 PromptTemplate 객체 생성"],"metadata":{"id":"HPQbbyRwpLSb"}},{"cell_type":"code","source":["from langchain_core.prompts import PromptTemplate\n","\n","# template 정의. {country}는 변수로, 이후에 값이 들어갈 자리를 의미\n","template = \"{country}의 수도는 어디인가요?\"\n","\n","# from_template 메소드를 이용하여 PromptTemplate 객체 생성\n","prompt = PromptTemplate.from_template(template)\n","prompt"],"metadata":{"id":"Pdt77F8DhwkH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# prompt 생성. format 메소드를 이용하여 변수에 값을 넣어줌\n","prompt = prompt.format(country=\"대한민국\")\n","prompt"],"metadata":{"id":"BDOEJRW_h3n5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Template(안에 우리가 받을 값을 변수로 가짐)-- from_template() 메소드--> prompt 제작 후\n","\n","chain으로 llm과 연결."],"metadata":{"id":"mJcwqHhgpk16"}},{"cell_type":"code","source":["# template 정의\n","template = \"{country}의 수도는 어디인가요?\"\n","\n","# from_template 메소드를 이용하여 PromptTemplate 객체 생성\n","prompt = PromptTemplate.from_template(template)\n","\n","# chain 생성\n","chain = prompt | llm"],"metadata":{"id":"DEoT9hLmjxvF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# country 변수에 입력된 값이 자동으로 치환되어 수행됨\n","chain.invoke(\"대한민국\").content"],"metadata":{"id":"5NUqAfJVkGb-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 방법 2. PromptTemplate 객체 생성과 동시에 prompt 생성"],"metadata":{"id":"_j-kesqFpTHe"}},{"cell_type":"markdown","source":["추가 유효성 검사를 위해 input_variables 를 명시적으로 지정하세요.\n","\n","이러한 변수는 인스턴스화 중에 템플릿 문자열에 있는 변수와 비교하여 불일치하는 경우 예외를 발생시킵니다."],"metadata":{"id":"SMoPZvyrqjUk"}},{"cell_type":"markdown","source":["`PromptTemplate()`으로 prompt 객체 생성"],"metadata":{"id":"ASgkXsBtu7ZL"}},{"cell_type":"code","source":["# template 정의\n","template = \"{country}의 수도는 어디인가요?\"\n","\n","# PromptTemplate 객체를 활용하여 prompt_template 생성\n","prompt = PromptTemplate(\n","    template=template,\n","    input_variables=[\"country\"], #!!\n",")\n","\n","prompt"],"metadata":{"id":"M9Jb6aP_pV3_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# prompt 생성\n","prompt.format(country=\"대한민국\")"],"metadata":{"id":"IsffgePjrGGI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Partial Variables를 이용한 유연성 확보"],"metadata":{"id":"MvPjtgcf9B1j"}},{"cell_type":"markdown","source":["### `partial_variables:` 부분 변수 채움\n","프롬프트 템플릿의 일부 변수에 미리 값을 할당해두는 기능"],"metadata":{"id":"Y9nLKwuv9fig"}},{"cell_type":"code","source":["# template 정의\n","template = \"{country1}과 {country2}의 수도는 각각 어디인가요?\"\n","\n","# PromptTemplate 객체를 활용하여 prompt_template 생성\n","prompt = PromptTemplate(\n","    template=template,\n","    input_variables=[\"country1\"],\n","    partial_variables={\n","        \"country2\": \"미국\"  # dictionary 형태로 partial_variables를 전달\n","    },\n",")\n","\n","prompt"],"metadata":{"id":"w7VW9--grcBM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt.format(country1=\"대한민국\")"],"metadata":{"id":"vYwScIJlsbCB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#  partial_variables의 country2가 미국->캐나다 변경\n","prompt_partial = prompt.partial(country2=\"캐나다\")\n","prompt_partial"],"metadata":{"id":"c3BrM3Ansmmo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["`promt.partial()`은\n","- 새로운 변수 자리를 생성(X)\n","- 이미 템플릿에 정의되어 있는 변수에 대해 미리 값을 할당하는 역할(O)\n","- 원래 prompt 객체 자체의 내부 내용을 수정하지 않음. 대신, 지정된 변수에 초기값이 할당된 새로운 PromptTemplate 객체를 생성해서 반환함."],"metadata":{"id":"hKlAOhvFtMG5"}},{"cell_type":"code","source":["prompt_partial.format(country1=\"대한민국\")"],"metadata":{"id":"Q_lM91bPttrA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["`format()` 메소드는 해당하는 변수에 값을 할당"],"metadata":{"id":"0WeijpKguuf9"}},{"cell_type":"code","source":["chain = prompt_partial | llm\n","chain.invoke(\"대한민국\").content"],"metadata":{"id":"smXgbIGeucBu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["chain.invoke({\"country1\": \"대한민국\", \"country2\": \"호주\"}).content"],"metadata":{"id":"UIwmTpzB2KiD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 사용 사례: **항상 공통된 방식으로 가져오고 싶은 변수** 가 있는 경우 (**날짜나 시간**)\n","`partial`을 사용하는 일반적인 용도는 함수를 부분적으로 사용하는 것."],"metadata":{"id":"sdy8wZRu21Nb"}},{"cell_type":"markdown","source":["예시:\n","날짜를 반환하는 함수 를 사용하여 프롬프트를 부분적으로 변경"],"metadata":{"id":"Lj7ri92H4Mn0"}},{"cell_type":"code","source":["#오늘 날짜를 구하는 파이썬 코드\n","from datetime import datetime\n","\n","# 날짜를 반환하는 함수 정의\n","def get_today():\n","    return datetime.now().strftime(\"%B %d\")"],"metadata":{"id":"QnQd6BoY4MIx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt = PromptTemplate(\n","    template=\"오늘의 날짜는 {today} 입니다. 오늘이 생일인 유명인 {n}명을 나열해 주세요. 생년월일을 표기해주세요.\",\n","    input_variables=[\"n\"],\n","    partial_variables={\n","        \"today\": get_today  # dictionary 형태로 partial_variables를 전달\n","    },\n",")"],"metadata":{"id":"dBc1waVn4arV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# prompt 생성\n","prompt.format(n=3)"],"metadata":{"id":"mqhIInP94pLy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# chain 을 생성합니다.\n","chain = prompt | llm\n","\n","# chain 을 실행 후 결과를 확인합니다.\n","print(chain.invoke(3).content)"],"metadata":{"id":"_KWbHwti4yv0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# chain 을 실행 후 결과를 확인합니다.\n","print(chain.invoke({\"today\": \"Jan 02\", \"n\": 3}).content)"],"metadata":{"id":"-Wd95Ugn6nT2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["`invoke` 메소드는\n","\n"," 단순히 LLM의 텍스트 응답뿐만 아니라, API 호출과 관련된 다양한 메타데이터와 정보를 함께 반환.\n","\n","- content: 이것이 LLM이 생성한 실제 텍스트 응답입니다. \"오늘이 생일인 유명인 3명\"에 대한 내용이 여기에 들어있습니다.\n","- additional_kwargs: 추가적인 키워드 인자나 정보가 담길 수 있는 딕셔너리입니다. 여기서는 refusal: None으로 특별한 추가 정보는 없습니다.\n","- response_metadata: LLM 모델 자체와 관련된 상세 정보입니다.\n","  - token_usage: 요청 및 응답에 사용된 토큰 수 (비용 계산 등에 사용될 수 있습니다).\n","  - model_name: 사용된 LLM 모델의 이름 (예: gpt-3.5-turbo-0125).\n","  - finish_reason: 응답 생성이 왜 중단되었는지 (예: stop은 정상적인 완료를 의미합니다).\n","  - 그 외 ID, 서비스 티어 등 API 호출과 관련된 정보가 포함됩니다.\n","- id: 이 특정 호출에 대한 고유 식별자입니다.\n","- usage_metadata: 전체 호출의 사용량 요약 정보입니다."],"metadata":{"id":"-l6nsVSQ52lp"}},{"cell_type":"markdown","source":["### 파일로부터 template 읽어오기"],"metadata":{"id":"P6pq7mTm7yqj"}},{"cell_type":"markdown","source":["주피터 노트북을 사용할 경우 파일을 읽어오는 방법-->"],"metadata":{"id":"Qv7gJOeyA-o9"}},{"cell_type":"code","metadata":{"id":"a258eb01"},"source":["from google.colab import drive\n","\n","# Google Drive 마운트\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3e27dcea"},"source":["\n","Drive 마운트가 완료되면, Google Drive에 업로드한 `fruit_color.yaml` 파일의 경로를 확인해야 합니다. 일반적으로 `/content/drive/MyDrive/` 아래에 파일이 위치하게 됩니다."]},{"cell_type":"code","source":["from langchain_core.prompts import load_prompt\n","\n","prompt = load_prompt(\"/content/drive/MyDrive/Colab Notebooks/Langchain/fruit_color.yaml\")\n","prompt"],"metadata":{"id":"HvwxPU5u7ye3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt.format(fruit=\"사과\")"],"metadata":{"id":"Az7O8WkiA8bM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt2 = load_prompt(\"/content/drive/MyDrive/Colab Notebooks/Langchain/capital.yaml\")\n","print(prompt2.format(country=\"대한민국\"))"],"metadata":{"id":"_xjWm-zZBPGQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### ChatPromptTemplate"],"metadata":{"id":"5B6ktslEBq49"}},{"cell_type":"markdown","source":["`ChatPromptTemplate`: 대화목록을 프롬프트로 주입하고자 할 때\n","\n","메시지는 튜플(tuple) 형식으로 구성하며, (`role, message`) 로 구성하여 리스트로 생성할 수 있습니다.\n","  - tuple: 순서가 정해진 값들의 집합\n","\n","**role**\n","- \"system\": 시스템 설정 메시지 입니다. 주로 전역설정과 관련된 프롬프트입니다.\n","- \"human\" : 사용자 입력 메시지 입니다.\n","- \"ai\": AI 의 답변 메시지입니다."],"metadata":{"id":"GUUHTY85BtTe"}},{"cell_type":"code","source":["from langchain_core.prompts import ChatPromptTemplate\n","\n","chat_prompt = ChatPromptTemplate.from_template(\"{country}의 수도는 어디인가요?\")\n","chat_prompt"],"metadata":{"id":"y8ORhUAPCjhZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["chat_prompt.format(country=\"대한민국\")"],"metadata":{"id":"UvJjCmP5CnQA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_core.prompts import ChatPromptTemplate\n","\n","chat_template = ChatPromptTemplate.from_messages(\n","    [\n","        # (role, message) <- tuple 한개, 여기 총 4개\n","        (\"system\", \"당신은 친절한 AI 어시스턴트입니다. 당신의 이름은 {name} 입니다.\"),\n","        (\"human\", \"반가워요!\"),\n","        (\"ai\", \"안녕하세요! 무엇을 도와드릴까요?\"),\n","        (\"human\", \"{user_input}\"),\n","    ]\n",")\n","\n","# 챗 message 를 생성합니다.\n","messages = chat_template.format_messages(\n","    name=\"테디\", user_input=\"당신의 이름은 무엇입니까?\"\n",")\n","messages"],"metadata":{"id":"zwj-tswZC26m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["llm.invoke(messages).content"],"metadata":{"id":"lMbwJyIRDEn3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["이번에는 체인을 생성해 보겠습니다."],"metadata":{"id":"88t1y7KwIDmw"}},{"cell_type":"code","source":["chain = chat_template | llm\n","chain.invoke({\"name\": \"Teddy\", \"user_input\": \"당신의 이름은 무엇입니까?\"}).content\n"],"metadata":{"id":"e8LHOw_kIERe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### `MessagePlaceholder`\n","긴 대화 기록이나 컨텍스트를 변수 형태로 받아와 프롬프트의 원하는 위치에 통째로 삽입 가능!\n","\n","\n","메시지 프롬프트 템플릿에 어떤 역할을 사용해야 할지 확실하지 않거나 서식 지정 중에 메시지 목록을 삽입하려는 경우 유용할 수 있습니다."],"metadata":{"id":"o4k9KSs8IlXd"}},{"cell_type":"code","source":["from langchain_core.output_parsers import StrOutputParser\n","from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n","\n","chat_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\n","            \"system\",\n","            \"당신은 요약 전문 AI 어시스턴트입니다. 당신의 임무는 주요 키워드로 대화를 요약하는 것입니다.\",\n","        ),\n","        MessagesPlaceholder(variable_name=\"conversation\"),\n","        (\"human\", \"지금까지의 대화를 {word_count} 단어로 요약합니다.\"),\n","    ]\n",")\n","chat_prompt\n"],"metadata":{"id":"UtVw08OYJx0B"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["conversation 대화목록을 나중에 추가하고자 할 때 MessagesPlaceholder 를 사용할 수 있습니다."],"metadata":{"id":"GyaAvC6fKhma"}},{"cell_type":"code","source":["formatted_chat_prompt = chat_prompt.format(\n","    word_count=5,\n","    conversation=[\n","        (\"human\", \"안녕하세요! 저는 오늘 새로 입사한 테디 입니다. 만나서 반갑습니다.\"),\n","        (\"ai\", \"반가워요! 앞으로 잘 부탁 드립니다.\"),\n","    ],\n",")\n","\n","print(formatted_chat_prompt)"],"metadata":{"id":"B7RX8hu8KiNM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# chain 생성\n","chain = chat_prompt | llm | StrOutputParser()\n","\n","# chain 실행 및 결과확인\n","chain.invoke(\n","    {\n","        \"word_count\": 5,\n","        \"conversation\": [\n","            (\n","                \"human\",\n","                \"안녕하세요! 저는 오늘 새로 입사한 테디 입니다. 만나서 반갑습니다.\",\n","            ),\n","            (\"ai\", \"반가워요! 앞으로 잘 부탁 드립니다.\"),\n","        ],\n","    }\n",")"],"metadata":{"id":"nUxSMKeGKqIa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["`StrOutputParser()`\n","\n","출력 파서 중 하나로, LLM 응답의 content를 문자열로 추출하는 역할을 한다."],"metadata":{"id":"7wCnmN1LKzk8"}},{"cell_type":"markdown","source":["## 02. 퓨샷 프롬프트(FewShotPromptTemplate)"],"metadata":{"id":"RcF8EYokL8i7"}},{"cell_type":"markdown","source":["Few-Shot Prompting:\n","\n","LLM에게 원하는 작업의 예시를 몇 개(Few-shot) 제공하여, 모델이 예시를 보고 학습하여 비슷한 스타일이나 형식으로 응답하도록 유도하는 방법.\n","\n"," Zero-Shot Prompting (예시 없이 질문만 하는 것)이나 One-Shot Prompting (예시 하나만 주는 것)보다 모델의 성능을 향상시키는 데 도움이 될 수 있습니다."],"metadata":{"id":"No3-BPAPwsV2"}},{"cell_type":"markdown","source":["**FewShotPromptTemplate**"],"metadata":{"id":"crmDWdZ7MCtN"}},{"cell_type":"code","source":["from langchain_openai import ChatOpenAI\n","from langchain_teddynote.messages import stream_response\n","\n","# 객체 생성\n","llm = ChatOpenAI(\n","    temperature=0,  # 창의성: 0->모델의 응답이 더 결정적이고 일관되게 됨.\n","    model_name=\"gpt-4-turbo\",  # 모델명\n",")"],"metadata":{"id":"ODsEsuVF791t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 질의내용\n","question = \"대한민국의 수도는 뭐야?\"\n","\n","# 질의\n","answer = llm.stream(question)\n","print(\"1.\")\n","print(answer)\n","print(\"2.\")\n","stream_response(answer)"],"metadata":{"id":"j3-i72XRxAn3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Q1. 위의 코드들에서는 prompt를 직접 만들어서 llm과 chain으로 연결한 후에 invoke해야했는데, FewShotPrompt 관련 코드에서는 왜 prompt를 생성하지 않고 string을 바로 llm에 넣어?\n","> 입력 변수가 없고 단순히 고정된 질문 하나를 LLM에게 전달하는 경우에는 굳이 PromptTemplate 객체를 생성하지 않고 프롬프트 문자열을 LLM의 `invoke나 stream` 메소드에 직접 전달해도 동작합니다.\n","\n","Q2. `invoke()`와 `stream()`의 차이점?\n","> invoke(): LLM에게 질문을 던지고 모든 답변이 완성될 때까지 기다립니다. 답변이 완전히 준비되면, 그 완성된 답변 전체를 한 번에 받아서 반환.\n","\n","\n","> stream(): 조금씩, 실시간으로 응답의 일부분(토큰)을 받습니다\n","\n","Q3. 그리고 왜 `print`를 사용하지 않고 `stream_response`라는 메소드를 사용해?\n","> 만약 stream()의 결과를 print()로 바로 출력하려고 하면, 스트림 객체 자체나 그 내부 표현이 출력.\n","\n","> ChatOpenAI() 객체에 .stream() 메소드를 사용하면, LLM의 응답이 한 번에 도착하는 것이 아니라 실시간으로 토큰 단위로 스트리밍되어 전달됩니다. 즉, 응답이 생성되는 대로 조금씩 받아볼 수 있습니다.\n","\n","\n","\n","\n"],"metadata":{"id":"atgwgTZ7z-3L"}},{"cell_type":"code","source":["from langchain_core.prompts.few_shot import FewShotPromptTemplate\n","from langchain_core.prompts import PromptTemplate\n","from langchain_core.output_parsers import StrOutputParser\n","\n","\n","examples = [\n","    {\n","        \"question\": \"스티브 잡스와 아인슈타인 중 누가 더 오래 살았나요?\",\n","        \"answer\": \"\"\"이 질문에 추가 질문이 필요한가요: 예.\n","추가 질문: 스티브 잡스는 몇 살에 사망했나요?\n","중간 답변: 스티브 잡스는 56세에 사망했습니다.\n","추가 질문: 아인슈타인은 몇 살에 사망했나요?\n","중간 답변: 아인슈타인은 76세에 사망했습니다.\n","최종 답변은: 아인슈타인\n","\"\"\",\n","    },\n","    {\n","        \"question\": \"네이버의 창립자는 언제 태어났나요?\",\n","        \"answer\": \"\"\"이 질문에 추가 질문이 필요한가요: 예.\n","추가 질문: 네이버의 창립자는 누구인가요?\n","중간 답변: 네이버는 이해진에 의해 창립되었습니다.\n","추가 질문: 이해진은 언제 태어났나요?\n","중간 답변: 이해진은 1967년 6월 22일에 태어났습니다.\n","최종 답변은: 1967년 6월 22일\n","\"\"\",\n","    },\n","    {\n","        \"question\": \"율곡 이이의 어머니가 태어난 해의 통치하던 왕은 누구인가요?\",\n","        \"answer\": \"\"\"이 질문에 추가 질문이 필요한가요: 예.\n","추가 질문: 율곡 이이의 어머니는 누구인가요?\n","중간 답변: 율곡 이이의 어머니는 신사임당입니다.\n","추가 질문: 신사임당은 언제 태어났나요?\n","중간 답변: 신사임당은 1504년에 태어났습니다.\n","추가 질문: 1504년에 조선을 통치한 왕은 누구인가요?\n","중간 답변: 1504년에 조선을 통치한 왕은 연산군입니다.\n","최종 답변은: 연산군\n","\"\"\",\n","    },\n","    {\n","        \"question\": \"올드보이와 기생충의 감독이 같은 나라 출신인가요?\",\n","        \"answer\": \"\"\"이 질문에 추가 질문이 필요한가요: 예.\n","추가 질문: 올드보이의 감독은 누구인가요?\n","중간 답변: 올드보이의 감독은 박찬욱입니다.\n","추가 질문: 박찬욱은 어느 나라 출신인가요?\n","중간 답변: 박찬욱은 대한민국 출신입니다.\n","추가 질문: 기생충의 감독은 누구인가요?\n","중간 답변: 기생충의 감독은 봉준호입니다.\n","추가 질문: 봉준호는 어느 나라 출신인가요?\n","중간 답변: 봉준호는 대한민국 출신입니다.\n","최종 답변은: 예\n","\"\"\",\n","    },\n","]\n"],"metadata":{"id":"xwJO3X4vxvsU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["example_prompt = PromptTemplate.from_template(\n","    \"Question:\\n{question}\\nAnswer:\\n{answer}\"\n",")\n","\n","print(example_prompt.format(**examples[0]))\n"],"metadata":{"id":"aT68fe8I3nGk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["딕셔너리 앞에 **를 붙이면, 해당 딕셔너리의 키-값 쌍들을 **함수의 키워드 인자(keyword arguments)**로 자동으로 풀어헤쳐서 전달해 줌.\n","\n","**examples[0]는 이 딕셔너리를 받아서 question=\"...\"과 answer=\"...\"라는 두 개의 키워드 인자로 분해함.\n","\n","그래서 example_prompt.format(**examples[0])는 실제로는 다음과 같이 호출되는 것과 같습니다:\n","\n","\n","```\n","example_prompt.format(\n","    question=\"스티브 잡스와 아인슈타인 중 누가 더 오래 살았나요?\",\n","    answer=\"\"\"이 질문에 추가 질문이 필요한가요: 예.\n","... (생략) ...\n","\"\"\"\n",")\n","```\n","\n"],"metadata":{"id":"sHyBg2CV92yB"}},{"cell_type":"markdown","source":["이 템플릿은 예시 데이터 리스트(examples), 각 예시의 형식을 정의하는 example_prompt, 그리고 사용자 질문이 들어갈 suffix로 구성됩니다."],"metadata":{"id":"88uAuFqK_oR4"}},{"cell_type":"code","source":["prompt = FewShotPromptTemplate(\n","    examples=examples,\n","    example_prompt=example_prompt,\n","    suffix=\"Question:\\n{question}\\nAnswer:\",\n","    input_variables=[\"question\"],\n",")\n","\n","question = \"Google이 창립된 연도에 Bill Gates의 나이는 몇 살인가요?\"\n","final_prompt = prompt.format(question=question)\n","print(final_prompt)"],"metadata":{"collapsed":true,"id":"kmOplUulBx64"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["`suffix` 사용자의 실제 질문이나 프롬프트가 들어갈 자리\n","\n","```\n","suffix=\"Question:\\n{question}\\nAnswer:\",\n","```\n","이는 Few-Shot 예시들이 모두 나열된 뒤에 \"Question:\\n{question}\\nAnswer:\" 라는 형식이 추가된다는 뜻입니다. 그리고 최종적으로 prompt.format(question=question)을 통해 사용자의 질문(question 변수)이 {question} 자리에 채워져서 LLM에게 전달될 프롬프트가 완성됩니다.\n","\n","따라서 suffix는 Few-Shot 예시 패턴을 보여준 후에, **모델이 실제로 응답해야 할 사용자의 입력 부분을 정의하는 템플릿 역할**을 합니다.\n"],"metadata":{"id":"BAup2aMGDSwl"}},{"cell_type":"code","source":["# 결과 출력\n","answer = llm.stream(final_prompt)\n","stream_response(answer)\n"],"metadata":{"id":"wQzFgo72DMcD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 위 코드들의 최종 병합본\n","prompt = FewShotPromptTemplate(\n","    examples=examples,\n","    example_prompt=example_prompt,\n","    suffix=\"Question:\\n{question}\\nAnswer:\",\n","    input_variables=[\"question\"],\n",")\n","\n","# chain 생성\n","chain = prompt | llm | StrOutputParser()\n","\n","# 결과 출력\n","answer = chain.stream(\n","    {\"question\": \"Google이 창립된 연도에 Bill Gates의 나이는 몇 살인가요?\"}\n",")\n","stream_response(answer)\n"],"metadata":{"id":"7fiOF9qXEi-H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Example Selector\n","예제가 많은 경우 프롬프트에 포함할 예제를 선택\n","\n","-> Example Selector는 이 작업을 담당하는 클래스입니다.\n","\n","- 참고: https://python.langchain.com/v0.1/docs/modules/model_io/prompts/example_selectors/"],"metadata":{"id":"jmeCMgmhFAsW"}},{"cell_type":"code","metadata":{"collapsed":true,"id":"33859240"},"source":["!pip install -qU langchain-chroma"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_core.example_selectors import (\n","    MaxMarginalRelevanceExampleSelector,\n","    SemanticSimilarityExampleSelector,\n",")\n","from langchain_openai import OpenAIEmbeddings\n","from langchain_chroma import Chroma\n","\n","# Vector DB 생성 (저장소 이름, 임베딩 클래스)\n","chroma = Chroma(\"example_selector\", OpenAIEmbeddings())\n","\n","example_selector = SemanticSimilarityExampleSelector.from_examples(\n","    # 여기에는 선택 가능한 예시 목록이 있습니다.\n","    examples,\n","    # 여기에는 의미적 유사성을 측정하는 데 사용되는 임베딩을 생성하는 임베딩 클래스가 있습니다.\n","    OpenAIEmbeddings(),\n","    # 여기에는 임베딩을 저장하고 유사성 검색을 수행하는 데 사용되는 VectorStore 클래스가 있습니다.\n","    Chroma,\n","    # 이것은 생성할 예시의 수입니다.\n","    k=1,\n",")\n","question = \"Google이 창립된 연도에 Bill Gates의 나이는 몇 살인가요?\"\n","# 입력과 가장 유사한 예시를 선택합니다.\n","selected_examples = example_selector.select_examples({\"question\": question})\n","\n","\n","print(f\"입력에 가장 유사한 예시:\\n{question}\\n\")\n","for example in selected_examples:\n","    print(f'question:\\n{example[\"question\"]}')\n","    print(f'answer:\\n{example[\"answer\"]}')\n"],"metadata":{"id":"mOgJayWGFKJT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**`Chroma`**는 **벡터 데이터베이스(Vector Database)**의 한 종류입니다.\n","\n","벡터 데이터베이스는 텍스트, 이미지, 오디오 등 다양한 데이터를 벡터(숫자 목록) 형태로 저장하고, 이 **벡터들 간의 유사성을 기반으로 빠르게 검색**하는 데 특화된 데이터베이스입니다.\n","\n","위 예시에서는 Chroma를 사용하여:\n","\n","examples (질문-답변 예시들)을 `OpenAIEmbeddings()`를 통해 벡터로 변환 ->\n","변환된 벡터들을 Chroma(\"example_selector\", ...)라는 Chroma 데이터베이스에 저장 ->\n","사용자의 새로운 질문({\"question\": question})도 벡터로 변환한 후, Chroma 데이터베이스에 저장된 예시 벡터들과 비교하여 의미적으로 가장 유사한 예시를 찾아냄.\n","\n","\n","즉, Chroma는 Few-Shot Prompting에서 사용할 \"가장 비슷한 예시\"를 효율적으로 검색하기 위해 사용되는 저장소 역할을 합니다."],"metadata":{"id":"aMiszzRXHmR_"}},{"cell_type":"markdown","source":["ExampleSelector 를 사용하여 FewShotPromptTemplate 을 생성 ->"],"metadata":{"id":"ON1N4Z5YM6kE"}},{"cell_type":"code","source":["prompt = FewShotPromptTemplate(\n","    example_selector=example_selector,\n","    example_prompt=example_prompt,\n","    suffix=\"Question:\\n{question}\\nAnswer:\",\n","    input_variables=[\"question\"],\n",")\n","\n","# 체인 생성\n","chain = prompt | llm\n","\n","# 결과 출력\n","answer = chain.stream(\n","    {\"question\": \"Google이 창립된 연도에 Bill Gates의 나이는 몇 살인가요?\"}\n",")\n","stream_response(answer)\n"],"metadata":{"id":"bMMJINYUHE-Q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### FewShotChatMessagePromptTemplate"],"metadata":{"id":"muHRX1GxNYsz"}},{"cell_type":"markdown","source":["일반 FewShot은 모든 내용을 하나의 긴 문자열로 넣는 반면, Chat Message 버전은 각 예시를 (human, ai) 쌍의 대화 메시지 목록 형태로 구성합니다.\n","\n","이는 모델에게 역할을 명확히 알려주기 때문에, 저희가 구현한 '회의록 작성 전문가'나 '문장 교정 전문가'와 같은 복잡한 역할극 프롬프트에 특히 효과적입니다."],"metadata":{"id":"ZfkfCkAoNmgu"}},{"cell_type":"code","source":["examples = [\n","    {\n","        \"instruction\": \"당신은 회의록 작성 전문가 입니다. 주어진 정보를 바탕으로 회의록을 작성해 주세요\",\n","        \"input\": \"2023년 12월 25일, XYZ 회사의 마케팅 전략 회의가 오후 3시에 시작되었다. 회의에는 마케팅 팀장인 김수진, 디지털 마케팅 담당자인 박지민, 소셜 미디어 관리자인 이준호가 참석했다. 회의의 주요 목적은 2024년 상반기 마케팅 전략을 수립하고, 새로운 소셜 미디어 캠페인에 대한 아이디어를 논의하는 것이었다. 팀장인 김수진은 최근 시장 동향에 대한 간략한 개요를 제공했으며, 이어서 각 팀원이 자신의 분야에서의 전략적 아이디어를 발표했다.\",\n","        \"answer\": \"\"\"\n","회의록: XYZ 회사 마케팅 전략 회의\n","일시: 2023년 12월 25일\n","장소: XYZ 회사 회의실\n","참석자: 김수진 (마케팅 팀장), 박지민 (디지털 마케팅 담당자), 이준호 (소셜 미디어 관리자)\n","\n","1. 개회\n","   - 회의는 김수진 팀장의 개회사로 시작됨.\n","   - 회의의 목적은 2024년 상반기 마케팅 전략 수립 및 새로운 소셜 미디어 캠페인 아이디어 논의.\n","\n","2. 시장 동향 개요 (김수진)\n","   - 김수진 팀장은 최근 시장 동향에 대한 분석을 제시.\n","   - 소비자 행동 변화와 경쟁사 전략에 대한 통찰 공유.\n","\n","3. 디지털 마케팅 전략 (박지민)\n","   - 박지민은 디지털 마케팅 전략에 대해 발표.\n","   - 온라인 광고와 SEO 최적화 방안에 중점을 둠.\n","\n","4. 소셜 미디어 캠페인 (이준호)\n","   - 이준호는 새로운 소셜 미디어 캠페인에 대한 아이디어를 제안.\n","   - 인플루언서 마케팅과 콘텐츠 전략에 대한 계획을 설명함.\n","\n","5. 종합 논의\n","   - 팀원들 간의 아이디어 공유 및 토론.\n","   - 각 전략에 대한 예산 및 자원 배분에 대해 논의.\n","\n","6. 마무리\n","   - 다음 회의 날짜 및 시간 확정.\n","   - 회의록 정리 및 배포는 박지민 담당.\n","\"\"\",\n","    },\n","    {\n","        \"instruction\": \"당신은 요약 전문가 입니다. 다음 주어진 정보를 바탕으로 내용을 요약해 주세요\",\n","        \"input\": \"이 문서는 '지속 가능한 도시 개발을 위한 전략'에 대한 20페이지 분량의 보고서입니다. 보고서는 지속 가능한 도시 개발의 중요성, 현재 도시화의 문제점, 그리고 도시 개발을 지속 가능하게 만들기 위한 다양한 전략을 포괄적으로 다루고 있습니다. 이 보고서는 또한 성공적인 지속 가능한 도시 개발 사례를 여러 국가에서 소개하고, 이러한 사례들을 통해 얻은 교훈을 요약하고 있습니다.\",\n","        \"answer\": \"\"\"\n","문서 요약: 지속 가능한 도시 개발을 위한 전략 보고서\n","\n","- 중요성: 지속 가능한 도시 개발이 필수적인 이유와 그에 따른 사회적, 경제적, 환경적 이익을 강조.\n","- 현 문제점: 현재의 도시화 과정에서 발생하는 주요 문제점들, 예를 들어 환경 오염, 자원 고갈, 불평등 증가 등을 분석.\n","- 전략: 지속 가능한 도시 개발을 달성하기 위한 다양한 전략 제시. 이에는 친환경 건축, 대중교통 개선, 에너지 효율성 증대, 지역사회 참여 강화 등이 포함됨.\n","- 사례 연구: 전 세계 여러 도시의 성공적인 지속 가능한 개발 사례를 소개. 예를 들어, 덴마크의 코펜하겐, 일본의 요코하마 등의 사례를 통해 실현 가능한 전략들을 설명.\n","- 교훈: 이러한 사례들에서 얻은 주요 교훈을 요약. 강조된 교훈에는 다각적 접근의 중요성, 지역사회와의 협력, 장기적 계획의 필요성 등이 포함됨.\n","\n","이 보고서는 지속 가능한 도시 개발이 어떻게 현실적이고 효과적인 형태로 이루어질 수 있는지에 대한 심도 있는 분석을 제공합니다.\n","\"\"\",\n","    },\n","    {\n","        \"instruction\": \"당신은 문장 교정 전문가 입니다. 다음 주어진 문장을 교정해 주세요\",\n","        \"input\": \"우리 회사는 새로운 마케팅 전략을 도입하려고 한다. 이를 통해 고객과의 소통이 더 효과적이 될 것이다.\",\n","        \"answer\": \"본 회사는 새로운 마케팅 전략을 도입함으로써, 고객과의 소통을 보다 효과적으로 개선할 수 있을 것으로 기대된다.\",\n","    },\n","]\n"],"metadata":{"id":"5FgnpdCoNaQT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n","from langchain_core.example_selectors import (\n","    SemanticSimilarityExampleSelector,\n",")\n","from langchain_openai import OpenAIEmbeddings\n","from langchain_chroma import Chroma\n","\n","chroma = Chroma(\"fewshot_chat\", OpenAIEmbeddings())\n","\n","example_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"human\", \"{instruction}:\\n{input}\"),\n","        (\"ai\", \"{answer}\"),\n","    ]\n",")\n","\n","example_selector = SemanticSimilarityExampleSelector.from_examples(\n","    # *예시 목록* 여기 있음~!\n","    examples,\n","    # 여기에는 의미적 *유사성을 측정*하는 데 사용되는 임베딩을 생성하는 임베딩 클래스가 있습니다.\n","    OpenAIEmbeddings(),\n","    # 여기에는 임베딩을 *저장*하고 유사성 검색을 수행하는 데 사용되는 VectorStore 클래스가 있습니다.\n","    chroma,\n","    # 이것은 생성할 예시의 수입니다.\n","    k=1,\n",")\n","\n","few_shot_prompt = FewShotChatMessagePromptTemplate( #!!\n","    example_selector=example_selector,\n","    example_prompt=example_prompt,\n",")\n","# example_selector는 전달받은 사용자 입력 (question)을 사용하여, 미리 설정된 examples 목록 중에서 **가장 유사한 예시 데이터**를 하나 또는 여러 개 선택합니다.\n","# few_shot_prompt는 선택된 예시 데이터를 example_prompt 틀에 넣어서 메시지 목록 형태로 변환\n","\n","# example_prompt 틀: [(\"human\", \"{instruction}:\\n{input}\"), (\"ai\", \"{answer}\")]\n","# 선택된 예시 데이터의 \"instruction\", \"input\", \"answer\" 값이 이 틀에 채워져서 HumanMessage와 AIMessage 객체로 구성된 예시 메시지 목록이 만들어집니다.\n","# 이렇게 만들어진 예시 메시지 목록이 최종 프롬프트 목록의 중간에 삽입됩니다.\n"],"metadata":{"id":"M-nLtzugIg_k"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["fewshot 예제와 example selector를 사용하여 유사한 예제 1개를 선택"],"metadata":{"id":"RLXC3KPMPlSF"}},{"cell_type":"code","source":["question = {\n","    \"instruction\": \"회의록을 작성해 주세요\",\n","    \"input\": \"2023년 12월 26일, ABC 기술 회사의 제품 개발 팀은 새로운 모바일 애플리케이션 프로젝트에 대한 주간 진행 상황 회의를 가졌다. 이 회의에는 프로젝트 매니저인 최현수, 주요 개발자인 황지연, UI/UX 디자이너인 김태영이 참석했다. 회의의 주요 목적은 프로젝트의 현재 진행 상황을 검토하고, 다가오는 마일스톤에 대한 계획을 수립하는 것이었다. 각 팀원은 자신의 작업 영역에 대한 업데이트를 제공했고, 팀은 다음 주까지의 목표를 설정했다.\",\n","}\n","\n","example_selector.select_examples(question)\n","# Q.example_selector 내부의 example_prompt에 우리가 추출한 유사도 높은 예시가 저장되나? NO\n","# 아래 텍스트에 이어서 설명"],"metadata":{"id":"CJL42ppjPkHI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["이 메소드를 호출하면 example_selector는 내부적으로 사용자의 question을 벡터화하고 Chroma DB에서 가장 유사한 예시(딕셔너리 형태)를 찾아서 그 결과를 반환합니다(위 출력물). 이 시점에서는 example_prompt 객체 자체는 아무런 변화가 없습니다."],"metadata":{"id":"P3Z2ppeNkouH"}},{"cell_type":"code","source":["final_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        ( #시스템 메세지\n","            \"system\",\n","            \"You are a helpful assistant.\",\n","        ),\n","        few_shot_prompt,  #!! 여기에 유사도 높은 example 있음\n","        ( # Human 메시지: 입력값의 \"instruction\"과 \"input\" 값이 채워짐.\n","         \"human\", \"{instruction}\\n{input}\"),\n","    ]\n",")\n","\n","# chain 생성\n","chain = final_prompt | llm\n","\n","# 실행 및 결과 출력\n","answer = chain.stream(question)\n","stream_response(answer)\n"],"metadata":{"id":"KvsDC_svRwUc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Example Selector 의 유사도 검색 문제 해결\n","\n","유사도 계산시 instruction 과 input 을 사용하고 있습니다. 하지만, instruction 만 사용하여 검색시 제대로된 유사도 결과가 나오지 않습니다.\n","\n","이를 해결하기 위해 커스텀 유사도 계산을 위한 클래스를 정의합니다.\n","\n","아래는 잘못 검색된 결과의 예시입니다."],"metadata":{"id":"4HENl9A5uwTE"}},{"cell_type":"code","source":["question = {\n","    \"instruction\": \"회의록을 작성해 주세요\",\n","}\n","\n","example_selector.select_examples(question)\n"],"metadata":{"id":"6vtfidOnr4hA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["커스텀 예제 선택기를 사용했을 때"],"metadata":{"id":"gbdqHTjrvRRY"}},{"cell_type":"code","source":["from langchain_teddynote.prompts import CustomExampleSelector\n","\n","# 커스텀 예제 선택기 생성\n","custom_selector = CustomExampleSelector(examples, OpenAIEmbeddings())\n","\n","# 커스텀 예제 선택기를 사용했을 때 결과\n","custom_selector.select_examples({\"instruction\": \"다음 문장을 교정 작성해 주세요\"})\n"],"metadata":{"id":"c0rNdg6avPKQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["example_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"human\", \"{instruction}:\\n{input}\"),\n","        (\"ai\", \"{answer}\"),\n","    ]\n",")\n","\n","custom_fewshot_prompt = FewShotChatMessagePromptTemplate(\n","    example_selector=custom_selector,  # 커스텀 예제 선택기 사용\n","    example_prompt=example_prompt,  # 예제 프롬프트 사용\n",")\n","\n","custom_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\n","            \"system\",\n","            \"You are a helpful assistant.\",\n","        ),\n","        custom_fewshot_prompt,\n","        (\"human\", \"{instruction}\\n{input}\"),\n","    ]\n",")"],"metadata":{"id":"ZyT54MonvWPn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# chain 을 생성합니다.\n","chain = custom_prompt | llm"],"metadata":{"id":"9Qa-irEevX5Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["question = {\n","    \"instruction\": \"회의록을 작성해 주세요\",\n","    \"input\": \"2023년 12월 26일, ABC 기술 회사의 제품 개발 팀은 새로운 모바일 애플리케이션 프로젝트에 대한 주간 진행 상황 회의를 가졌다. 이 회의에는 프로젝트 매니저인 최현수, 주요 개발자인 황지연, UI/UX 디자이너인 김태영이 참석했다. 회의의 주요 목적은 프로젝트의 현재 진행 상황을 검토하고, 다가오는 마일스톤에 대한 계획을 수립하는 것이었다. 각 팀원은 자신의 작업 영역에 대한 업데이트를 제공했고, 팀은 다음 주까지의 목표를 설정했다.\",\n","}\n","\n","# 실행 및 결과 출력\n","stream_response(chain.stream(question))\n"],"metadata":{"id":"CUpzb5w_vb5j"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 03. LangChain Hub"],"metadata":{"id":"whNs9VgA1FqV"}},{"cell_type":"markdown","source":["LangChain Hub (깃허브 아님 주의) 에서 프롬프트를 받아서 실행하는 예제!\n","\n","받아오는 방법은\n","- '프롬프트 repo 의 아이디 값'을 가져 올 수 있고,\n","- 'commit id' 를 붙여서 **특정 버전**에 대한 프롬프트를 받아올 수도 있습니다."],"metadata":{"id":"km3A0-2W1IJc"}},{"cell_type":"markdown","source":["### Hub로부터 Prompt 받아오기"],"metadata":{"id":"3qi8o88-a77B"}},{"cell_type":"code","source":["from langchain import hub\n","\n","# 가장 최신 버전의 프롬프트를 가져옵니다.\n","prompt = hub.pull(\"rlm/rag-prompt\")\n","# rlm라는 사용자가 게시, rag-prompt: 해당 프롬프트의 이름\n","\n","# 프롬프트 내용 출력\n","print(prompt)"],"metadata":{"id":"j81vE16Gb8lL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 특정 버전의 프롬프트를 가져오려면 버전 해시를 지정하세요\n","prompt = hub.pull(\"rlm/rag-prompt:50442af1\") #버전 :50442af1\n","prompt"],"metadata":{"id":"ZZdxk8WdarOE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Prompt Hub 에 자신의 프롬프트 등록"],"metadata":{"id":"Bv_rxaD4d0-a"}},{"cell_type":"code","source":["import os\n","from google.colab import userdata\n","from langchain.prompts import ChatPromptTemplate\n","from langchain import hub\n","\n","# 프롬프트 정의\n","prompt = ChatPromptTemplate.from_template(\n","    \"주어진 내용을 바탕으로 다음 문장을 요약하세요. 답변은 반드시 한글로 작성하세요\\n\\nCONTEXT: {context}\\n\\nSUMMARY:\"\n",")\n","\n","# 프롬프트를 허브에 업로드합니다.\n","hub.push(\"no-glass-otacku/simple-summary-korean\", prompt)"],"metadata":{"collapsed":true,"id":"exaM2EaxeEAu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Hub에 푸시할 때 LangSmith가 필요한 이유:\n","- LangSmith는 LangChain Hub의 기반 인프라 역할을 합니다. LangChain Hub는 LangSmith 플랫폼 위에서 운영되는 서비스의 일부입니다.\n","- LangSmith는 LangChain 컴포넌트(프롬프트 등)를 공유하고 관리하는 기능도 포함하고 있습니다.\n","- 따라서 Hub에 프롬프트를 업로드(푸시)하는 것은 LangSmith 플랫폼을 통해 이루어지며, 이때 사용자를 식별하고 권한을 확인하기 위해 LangSmith API 키를 통한 인증 과정이 필요합니다."],"metadata":{"id":"qSeijJlhiRGi"}},{"cell_type":"markdown","source":["## 04. 개인화된 프롬프트(Hub에 업로드)"],"metadata":{"id":"M3fATlZfQXvk"}},{"cell_type":"code","source":["# 1. 라이브러리 임포트 (아직 hub는 건드리지 않습니다)\n","from google.colab import userdata\n","import os\n","from langsmith import Client\n","\n","# 2. API 키 설정 (가장 중요)\n","# LANGCHAIN_API_KEY는 반드시 Colab Secrets에 등록된 이름이어야 합니다.\n","api_key_value = userdata.get(\"LANGCHAIN_API_KEY\")\n","os.environ[\"LANGCHAIN_API_KEY\"] = api_key_value\n","print(f\"API Key Load Success: {bool(api_key_value)}\")\n","\n","# 3. LangSmith Client 명시적 초기화\n","# 이 단계를 통해 환경 변수를 강제로 읽도록 합니다.\n","client = Client(api_key=api_key_value)\n","\n","# 4. 트레이싱 및 프로젝트 설정\n","os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n","os.environ[\"LANGCHAIN_PROJECT\"] = \"hub-upload-practice\"\n","\n","# 5. 이제 Hub를 임포트 (환경 변수가 설정된 후에 임포트되어야 함)\n","from langchain import hub\n","\n","# Owner 지정 (당신의 닉네임)\n","PROMPT_OWNER = \"no-glass-otacku\"\n","\n","# 이 셀 실행 후, 다음 셀에서 hub.push()를 실행합니다.\n","print(\"LangSmith 환경 설정 완료. 이제 hub.push()를 시도하세요.\")"],"metadata":{"id":"21y-It07VXOb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## LangChain에서 문서를 처리하거나 특정 Task를 수행하기 위해 자주 사용되는 프롬프트 패턴들 -6가지"],"metadata":{"id":"h6WHjHcnr6Sm"}},{"cell_type":"markdown","source":["### **1. Stuff Documents (문서 뭉치기)**\n","- 가장 간단한 문서 처리 방식으로, 모든 문서의 내용을 한 프롬프트 안에 뭉쳐 넣는(Stuff) 방식입니다.\n","- 개념: 검색된 모든 문서 덩어리(chunk)를 그대로 하나의 LLM 입력 프롬프트의 {context} 변수에 넣어 LLM에게 전달합니다.\n"," - 장점: LLM이 전체 문맥을 한 번에 파악할 수 있어 가장 정확한 결과를 얻을 수 있습니다.\n"," - 단점: 입력 토큰 제한(Context Window)을 쉽게 초과하여 긴 문서에는 적용할 수 없습니다.\n","\n","\n","\n"],"metadata":{"id":"yQ29_g2fipYp"}},{"cell_type":"code","source":["from langchain import hub\n","from langchain.prompts import PromptTemplate\n","\n","prompt_title = \"summary-stuff-documents\"\n","\n","# 요약문을 작성하기 위한 프롬프트 정의 (직접 프롬프트를 작성하는 경우)\n","prompt_template = \"\"\"Please summarize the sentence according to the following REQUEST.\n","REQUEST:\n","1. Summarize the main points in bullet points.\n","2. Each summarized sentence must start with an emoji that fits the meaning of the each sentence.\n","3. Use various emojis to make the summary more interesting.\n","4. DO NOT include any unnecessary information.\n","\n","CONTEXT:\n","{context}\n","\n","SUMMARY:\"\n","\"\"\"\n","prompt = PromptTemplate.from_template(prompt_template)\n","prompt"],"metadata":{"id":"KK-UdB3IR8Fj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["hub.push(f\"{PROMPT_OWNER}{prompt_title}\", prompt)"],"metadata":{"id":"NEmKwlVqS4ER"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Map Prompt"],"metadata":{"id":"kbBlgUBWhwAo"}},{"cell_type":"markdown","source":["**2. Map Prompt**\n","- 문서를 작은 덩어리로 나눈 뒤, 각 덩어리마다 동일한 프롬프트를 적용하여 처리 (주로 Map-Reduce 체인의 Map 단계에 사용)\n","- 장점: 토큰 제한을 피할 수 있으며, 병렬 처리가 가능\n","- 단점: 최종 결과를 통합하는 추가 단계(Reduce)가 필요하며, 문서 전체의 흐름(거시적 문맥)을 놓칠 수 있음.\n"],"metadata":{"id":"Z79XbEAQqdo-"}},{"cell_type":"code","source":["from langchain import hub\n","from langchain.prompts import PromptTemplate\n","\n","prompt_title = \"map-prompt\"\n","\n","# 요약문을 작성하기 위한 프롬프트 정의 (직접 프롬프트를 작성하는 경우)\n","prompt_template = \"\"\"You are a helpful expert journalist in extracting the main themes from a GIVEN DOCUMENTS below.\n","Please provide a comprehensive summary of the GIVEN DOCUMENTS in numbered list format.\n","The summary should cover all the key points and main ideas presented in the original text, while also condensing the information into a concise and easy-to-understand format.\n","Please ensure that the summary includes relevant details and examples that support the main ideas, while avoiding any unnecessary information or repetition.\n","The length of the summary should be appropriate for the length and complexity of the original text, providing a clear and accurate overview without omitting any important information.\n","\n","GIVEN DOCUMENTS:\n","{docs}\n","\n","FORMAT:\n","1. main theme 1\n","2. main theme 2\n","3. main theme 3\n","...\n","\n","CAUTION:\n","- DO NOT list more than 5 main themes.\n","\n","Helpful Answer:\n","\"\"\"\n","prompt = PromptTemplate.from_template(prompt_template)\n","prompt\n"],"metadata":{"id":"J8Z6EzyjhvnD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["hub.push(f\"{PROMPT_OWNER}{prompt_title}\", prompt)"],"metadata":{"id":"stT_2gKehz_H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **3. Reduce Prompt (축소 프롬프트)**\n","- Map 단계에서 생성된 여러 개의 중간 결과(예: 부분 요약)를 하나로 합쳐 최종 결과를 만드는 데 사용됩니다. (주로 Map-Reduce 체인의 Reduce 단계에 사용)\n","- 개념: Map 단계에서 나온 결과물들(여러 개의 요약, 답변 등)을 모아 하나의 프롬프트로 만든 후, LLM에게 최종 통합/정리 작업을 요청합니다.\n","\n","- 장점: 여러 개의 중간 결과를 일관성 있는 최종 결과로 만듭니다.\n","\n","- 단점: 통합 과정에서 또다시 토큰 제한에 부딪힐 수 있습니다.\n","\n","```\n","\"다음은 여러 부분 요약(Part Summaries)들입니다. 이를 종합하여 하나의 응집력 있고 상세한 최종 요약(Final Summary)을 만드세요. \\n\\nPART SUMMARIES:\\n{context}\\n\\nFINAL SUMMARY:\"\n","```\n"],"metadata":{"id":"2ObGoXdTqiJG"}},{"cell_type":"code","source":["# 요약문을 작성하기 위한 프롬프트 정의 (직접 프롬프트를 작성하는 경우)\n","prompt_template = \"\"\"You are a helpful expert in summary writing.\n","You are given numbered lists of summaries.\n","Extract top 10 most important insights from the summaries.\n","Then, write a summary of the insights in KOREAN.\n","\n","LIST OF SUMMARIES:\n","{doc_summaries}\n","\n","Helpful Answer:\n","\"\"\""],"metadata":{"id":"spX0OM_lqyy8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 요약문을 작성하기 위한 프롬프트 정의 (직접 프롬프트를 작성하는 경우)\n","prompt_template = \"\"\"You are a helpful expert in summary writing. You are given lists of summaries.\n","Please sum up previously summarized sentences according to the following REQUEST.\n","REQUEST:\n","1. Summarize the main points in bullet points in KOREAN.\n","2. Each summarized sentence must start with an emoji that fits the meaning of the each sentence.\n","3. Use various emojis to make the summary more interesting.\n","4. MOST IMPORTANT points should be organized at the top of the list.\n","5. DO NOT include any unnecessary information.\n","\n","LIST OF SUMMARIES:\n","{doc_summaries}\n","\n","Helpful Answer: \"\"\""],"metadata":{"id":"jGuIzOTjq5Vi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **4. Metadata Tagger (메타데이터 태그 지정)**\n","- 제공된 텍스트에서 구조화된 정보(메타데이터)를 추출\n","- 개념: 문서나 텍스트를 분석하여, 미리 정의된 스키마(예: JSON 형식)에 맞춰 이름, 날짜, 키워드, 카테고리 등의 메타데이터를 추출하도록 LLM에게 요청합니다.\n","\n","- 장점: 비정형 텍스트를 검색이나 필터링에 유용한 정형 데이터로 변환\n","\n"],"metadata":{"id":"frzyW_VFqk2V"}},{"cell_type":"code","source":["prompt_template = \"\"\"Given the following product review, conduct a comprehensive analysis to extract key aspects mentioned by the customer, with a focus on evaluating the product's design and distinguishing between positive aspects and areas for improvement.\n","Identify primary features or attributes of the product that the customer appreciated or highlighted, specifically looking for mentions related to the feel of the keys, sound produced by the keys, overall user experience, charging aspect, and the design of the product, etc.\n","Assess the overall tone of the review (positive, neutral, or negative) based on the sentiment expressed about these attributes.\n","Additionally, provide a detailed evaluation of the design, outline the positive aspects that the customer enjoyed, and note any areas of improvement or disappointment mentioned.\n","Extract the customer's rating of the product on a scale of 1 to 5, as indicated at the beginning of the review.\n","Summarize your findings in a structured JSON format, including an array of keywords, evaluations for design, satisfaction points, improvement areas, the assessed tone, and the numerical rating.\n","\n","INPUT:\n","{input}\n","\n","\"\"\""],"metadata":{"id":"YQgMwu8_rKQ_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **5. Chain of Density 요약**\n","- 한 번에 완성된 요약을 만드는 것이 아니라, 점진적으로 정보를 추가하며 요약의 밀도(Density)를 높이도록 LLM을 유도하는 프롬프트 체인\n","- 개념: 먼저 기본적인 요약을 만들게 한 후, 다음 단계에서는 이 요약에 누락된 핵심 엔티티나 정보를 추가하여 요약을 계속 수정하고 확장하도록 반복적으로 지시합니다.\n","- 장점: 정보가 풍부하고 세부 사항을 놓치지 않는 '밀도 높은' 요약을 생성합니다. (기존 요약보다 정보량이 많음)\n","\n","\n","```\n","1단계 (기본 요약): \"다음 기사를 하나의 문단으로 요약하세요.\"\n","2단계 (밀도 증가): \"위 요약을 수정하여 기사의 핵심 엔티티 1~3개를 추가하세요. 요약의 길이는 유지해야 합니다. \\n\\nOriginal Summary:\\n{summary}\\n\\nModified Summary:\"**\n","```\n","\n"],"metadata":{"id":"qEvkx8qFqmyO"}},{"cell_type":"code","source":["prompt = ChatPromptTemplate.from_template(\n","    \"\"\"Article: {ARTICLE}\n","You will generate increasingly concise, entity-dense summaries of the above article.\n","\n","Repeat the following 2 steps 5 times.\n","\n","Step 1. Identify 1-3 informative entities (\";\" delimited) from the article which are missing from the previously generated summary.\n","Step 2. Write a new, denser summary of identical length which covers every entity and detail from the previous summary plus the missing entities.\n","\n","A missing entity is:\n","- relevant to the main story,\n","- specific yet concise (100 words or fewer),\n","- novel (not in the previous summary),\n","- faithful (present in the article),\n","- anywhere (can be located anywhere in the article).\n","\n","Guidelines:\n","\n","- The first summary should be long (8-10 sentences, ~200 words) yet highly non-specific, containing little information beyond the entities marked as missing. Use overly verbose language and fillers (e.g., \"this article discusses\") to reach ~200 words.\n","- Make every word count: rewrite the previous summary to improve flow and make space for additional entities.\n","- Make space with fusion, compression, and removal of uninformative phrases like \"the article discusses\".\n","- The summaries should become highly dense and concise yet self-contained, i.e., easily understood without the article.\n","- Missing entities can appear anywhere in the new summary.\n","- Never drop entities from the previous summary. If space cannot be made, add fewer new entities.\n","\n","Remember, use the exact same number of words for each summary.\n","Answer in JSON. The JSON should be a list (length 5) of dictionaries whose keys are \"Missing_Entities\" and \"Denser_Summary\".\n","Use only KOREAN language to reply.\"\"\"\n",")"],"metadata":{"id":"qa0vXydfrSpx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **6. RAG 문서 프롬프트**\n","- RAG 시스템에서 검색된 문서를 LLM에게 전달할 때 사용 (주로 Stuff, Map, Reduce 체인 내부에서 사용)\n","- 개념: 검색 시스템이 찾아낸 원본 문서 청크를 LLM이 답변을 생성하는 데 필요한 **'컨텍스트'**로 제공하는 역할을 합니다.\n","\n","- 장점: LLM이 환각(Hallucination)을 줄이고 최신 정보나 내부 데이터를 기반으로 답변하도록 강제\n","\n","```\n","\"검색된 다음 컨텍스트를 참고하여 질문에 가장 정확하고 완전한 답변을 제공하십시오. 컨텍스트에 없는 내용은 언급하지 마십시오. \\n\\nCONTEXT:\\n{context}\\n\\nQUESTION:\\n{question}\"\n","```"],"metadata":{"id":"wT8PQGyCqove"}},{"cell_type":"code","source":["system = \"\"\"당신은 질문-답변(Question-Answering)을 수행하는 친절한 AI 어시스턴트입니다. 당신의 임무는 주어진 문맥(context) 에서 주어진 질문(question) 에 답하는 것입니다.\n","검색된 다음 문맥(context) 을 사용하여 질문(question) 에 답하세요. 만약, 주어진 문맥(context) 에서 답을 찾을 수 없다면, 답을 모른다면 `주어진 정보에서 질문에 대한 정보를 찾을 수 없습니다` 라고 답하세요.\n","한글로 답변해 주세요. 단, 기술적인 용어나 이름은 번역하지 않고 그대로 사용해 주세요. Don't narrate the answer, just answer the question. Let's think step-by-step.\"\"\"\n","\n","human = \"\"\"#Question:\n","{question}\n","\n","#Context:\n","{context}\n","\n","#Answer:\"\"\"\n","\n","from langchain.prompts import ChatPromptTemplate\n","\n","\n","prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", human)])"],"metadata":{"id":"fo1OpUgArdDw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["hub.push(f\"{PROMPT_OWNER}/{prompt_title}\", prompt, parent_commit_hash=\"latest\")\n"],"metadata":{"id":"WUgG4b1mriT3"},"execution_count":null,"outputs":[]}]}