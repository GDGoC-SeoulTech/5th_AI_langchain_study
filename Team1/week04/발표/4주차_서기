최대한 실행을 해보려고 하였으나 어려움이 있었던 이유로 개념 위주로 설명

## Cache

API 비용과 시간을 줄이기 위해 캐싱 사용
이전에 물어본 것과 같은 것을 물어보면 저장을 해둔 것을 찾아 답변 하는 형식

1. InMemory Cache 방식
  - 세션을 하는 동안에만 유지
  - 개발 중에 임시로 사용하기 좋음
2. SQLite Cache
  - 로컬db에 저장하여 영구적으로 사용 가능

SQLite 방식은 디렉토리를 생성해서 접근하는데 시간이 걸리기 때문에 InMemory보다 시간이 조금 더 걸림

실험해본 결과, 완전히 같은 프롬프트여야만 가능
ex) 요약해줘, 요약해주세요를 완전히 다른 것으로 여김

이때 유사도 기반 캐시를 사용해서 해당 문제를 해결할 수 있다고 소개


## 직렬화

직렬화는 LangChain 객체를 저정하는 과정, 저장한 내용을 다시 로드하여 사용하는 것을 역직렬화라고 함

dumpd, dumps를 사용하여 체인을 데이터로 바꿀 수 있음

- dumpd : key-value 형태
- dumps : json 형태


## 토큰 사용량 확인
callback() 함수를 써서 확인할 수 있음
실무에서 많이 사용한다고 함.
어떤 부분에서 토큰을 많이 잡아먹는지 확인할 수 있음


## Hugging face

AI 모델들이 올라와 있는데 오픈소스 플랫폼

API형태로 모델을 사용할 수 있는 endpoint를 제공해줘서 사용이 쉬움
이를 사용하여 모델을 돌려보는 실습을 진행함

- Serverless endpoint
- Inference endpoint


hugging face local을 사용하면 인터넷 연결없이도 사용할 수 있음
다운로드해서 사용하는 방식


hugging face pipeline
한번에 모델, 입력, 출력을 처리할 수 잇음
pipeline은 모델을 한번에 사용할 수 있도록 해주는 함수임


## 질문

- 신형: gemini 돌릴 때 환경 결과에 대해 질문
- 제근: 본인이 돌려본 내용에 대해 답변
- 지원: 유사도 기반 캐시의 작동 과정을 설명: 임베딩 모델 활용 -> 유사도 계산
